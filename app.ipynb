{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r /home/harsh/Documents/RAG/requirements -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sk-proj-WSb39FTU97JTHmcZg9oDT3BlbkFJ3qkIBAqdpbcnjuZwtV1S'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "llm = ChatOpenAI(model = 'gpt-3.5-turbo')\n",
    "# output = llm.invoke(\"Explain quantum mechanics in one sentence\")\n",
    "# print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG (Retrieval-Augmented Generation) AI technique hai jo natural language processing (NLP) mein istemal hota hai. Is technique mein retrieval-based model aur generation-based model ko combine kiya jata hai. Retrieval-based model text ko samajhne aur relevant information ko retrieve karne mein mahir hota hai, jabki generation-based model naye text ko generate karne mein upyog hota hai. RAG AI technique ke dwara text generation ko improve kiya jata hai, kyunki yeh retrieval ki madad se context aur information ko better understand karta hai.\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage, \n",
    "    AIMessage\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a scientist and you respond only in Hindi\"),\n",
    "    HumanMessage(content = \"Explain what is RAG in AI\")\n",
    "]\n",
    "output = llm.invoke(messages)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching LLM responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### InMemoryCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache # type: ignore\n",
    "from langchain_openai import OpenAI    # type: ignore\n",
    "llm = OpenAI(model_name = 'gpt-3.5-turbo-instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.9 ms, sys: 2.16 ms, total: 43.1 ms\n",
      "Wall time: 2.27 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nWhy was the math book sad? Because it had too many problems!'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "from langchain.cache import InMemoryCache\n",
    "set_llm_cache(InMemoryCache())\n",
    "prompt = 'Tell me a joke that a toddler can understand'\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 737 μs, sys: 73 μs, total: 810 μs\n",
      "Wall time: 823 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nWhy was the math book sad? Because it had too many problems!'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### printing streamline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Why did the banana go to the doctor? Because it wasn't peeling well!\n",
      "2. Why did the cookie go to the doctor? Because it was feeling crumbly!\n",
      "3. Why did the scarecrow win an award? Because he was outstanding in his field!\n",
      "4. Why was the math book sad? Because it had too many problems!\n",
      "5. Why did the tomato turn red? Because it saw the salad dressing!"
     ]
    }
   ],
   "source": [
    "prompt = 'Tell me 5 joke that a toddler can understand'\n",
    "for chunk in llm.stream(prompt):\n",
    "    print(chunk.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Langchain prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coronavirus, also known as COVID-19, is a highly contagious respiratory virus that has caused a global pandemic. It originated in Wuhan, China in late 2019 and has since spread to nearly every country in the world. The virus primarily spreads through respiratory droplets and can cause symptoms ranging from mild cold-like symptoms to severe respiratory illness and death. Efforts to control the spread of the virus include social distancing, wearing masks, and vaccination campaigns.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "template = '''You are an experience virologist\n",
    "write a few sentences about {virus} in {language}\n",
    "'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "prompt = prompt_template.format(virus='corona', language = 'English')\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0)\n",
    "output = llm.invoke(prompt)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatPromptTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"1\": \"Germany\",\n",
      "    \"2\": \"Russia\",\n",
      "    \"3\": \"Turkey\",\n",
      "    \"4\": \"France\",\n",
      "    \"5\": \"United Kingdom\",\n",
      "    \"6\": \"Italy\",\n",
      "    \"7\": \"Spain\",\n",
      "    \"8\": \"Ukraine\",\n",
      "    \"9\": \"Poland\",\n",
      "    \"10\": \"Romania\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, PromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content='You respond only in JSON format'),\n",
    "        HumanMessagePromptTemplate.from_template('Top {n} countries in {area} by population. Just give the ranking of the coutries and nothing else')\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(n='10', area='Europe')\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "output = llm.invoke(messages)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OpenAI is an artificial intelligence research lab that aims to ensure that artificial general intelligence (AGI) benefits all of humanity. They conduct research in various AI-related fields and work on developing cutting-edge AI technologies. Additionally, OpenAI promotes openness and collaboration in the field of AI research.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "    (\"human\", \"Hello, how are you doing?\"),\n",
    "    (\"ai\", \"I'm doing well, thanks!\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "prompt_value = template.invoke({\n",
    "    \"name\": \"Bob\",\n",
    "    \"user_input\": \"Tell me something about OpenAI company\"\n",
    "})\n",
    "\n",
    "llm.invoke(prompt_value).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an experience virologist\n",
      "write a few sentences about corona in English\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "template = '''You are an experience virologist\n",
    "write a few sentences about {virus} in {language}\n",
    "'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template = template)\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = prompt_template,\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "output = chain.invoke({'virus': 'corona', 'language': 'English'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'virus': 'corona',\n",
       " 'language': 'English',\n",
       " 'text': 'Coronavirus, also known as COVID-19, is a novel virus that emerged in late 2019 and has since spread rapidly across the globe, causing a pandemic. It is a highly contagious virus that primarily spreads through respiratory droplets when an infected person coughs or sneezes. Symptoms of COVID-19 can range from mild flu-like symptoms to severe respiratory illness, and can be particularly dangerous for the elderly and those with underlying health conditions. Efforts to control the spread of the virus have included widespread testing, social distancing, mask-wearing, and the development of vaccines. As a virologist, my expertise lies in studying the biology and behavior of viruses like coronavirus in order to better understand and combat them.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWhat is the capital of Indi? List the top 3 places to visit in that city. Use bullet points to show the answer\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "template = 'What is the capital of {country}? List the top 3 places to visit in that city. Use bullet points to show the answer'\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = prompt_template,\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "country = input('Enter country: ')\n",
    "output = chain.invoke(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of India is New Delhi. \\n\\nSome of the top places to visit in New Delhi are:\\n- Red Fort\\n- India Gate\\n- Qutub Minar'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mHere is a simple function using the OpenCV library in Python to read an image file and display it:\n",
      "\n",
      "```python\n",
      "import cv2\n",
      "\n",
      "def display_image(image_path):\n",
      "    # Read the image file\n",
      "    image = cv2.imread(image_path)\n",
      "    \n",
      "    # Display the image\n",
      "    cv2.imshow('Image', image)\n",
      "    cv2.waitKey(0)\n",
      "    cv2.destroyAllWindows()\n",
      "\n",
      "# Example usage\n",
      "image_path = 'example.jpg'\n",
      "display_image(image_path)\n",
      "```\n",
      "\n",
      "This function reads an image file from the specified path using `cv2.imread()` and displays it using `cv2.imshow()`. The function `cv2.waitKey(0)` waits indefinitely for a key press to close the image window, and `cv2.destroyAllWindows()` closes all OpenCV windows.\n",
      "\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mThe function `display_image` in the provided Python script is designed to load and show an image using the OpenCV library, which is a popular library for computer vision tasks. The script is structured into three main parts: the import statement, the function definition, and an example usage. Here are the details of each part:\n",
      "\n",
      "1. **Import Statement:**\n",
      "   ```python\n",
      "   import cv2\n",
      "   ```\n",
      "   This line imports the OpenCV library and binds it to the name `cv2`. This import is necessary to access functions from the OpenCV library, which are used to read, display, and manipulate the image.\n",
      "\n",
      "2. **Function Definition:**\n",
      "   ```python\n",
      "   def display_image(image_path):\n",
      "       # Read the image file\n",
      "       image = cv2.imread(image_path)\n",
      "       \n",
      "       # Display the image\n",
      "       cv2.imshow('Image', image)\n",
      "       cv2.waitKey(0)\n",
      "       cv2.destroyAllWindows()\n",
      "   ```\n",
      "   - **Function Signature (`display_image(image_path)`):**\n",
      "     The function is named `display_image` and takes one parameter, `image_path`, which is a string representing the filesystem path to the image file to be displayed.\n",
      "\n",
      "   - **Reading the Image (`cv2.imread(image_path)`):**\n",
      "     Inside the function, `cv2.imread(image_path)` is called to load an image from the specified `image_path`. The returned result is stored in the variable `image`. This function returns the image as a numpy array if the path is valid and the file is successfully read, otherwise it returns `None`.\n",
      "\n",
      "   - **Displaying the Image (`cv2.imshow('Image', image)`):**\n",
      "     The `cv2.imshow` function creates a window named 'Image' and displays the loaded image `image` in this window. If `image` is `None` because the image was not loaded properly (due to an invalid path or the file not existing), this function might generate an error because it expects a proper image array.\n",
      "\n",
      "   - **Waiting for a Key Press (`cv2.waitKey(0)`):**\n",
      "     `cv2.waitKey(0)` causes the program to pause its execution until a key is pressed. The argument `0` means it will wait indefinitely for a key press. This pause allows users to view the image until they decide to proceed by pressing a key.\n",
      "\n",
      "   - **Closing the Windows (`cv2.destroyAllWindows()`):**\n",
      "     After a key is pressed, `cv2.destroyAllWindows()` is called, which simply closes all the windows that were opened by the program, i.e., the 'Image' window which was displaying our `image`.\n",
      "   \n",
      "3. **Example Usage:**\n",
      "   ```python\n",
      "   image_path = 'example.jpg'\n",
      "   display_image(image_path)\n",
      "   ```\n",
      "   In this part of the script:\n",
      "   - An `image_path` variable is set to the string 'example.jpg', specifying an image file.\n",
      "   - The `display_image` function is then called with the `image_path` argument pointing to \"example.jpg\".\n",
      "\n",
      "Overall, the script is a straightforward way to load and display an image using the OpenCV library in Python, emphasizing file operations and user interaction through keyboard input to control the display of the image. The function is particularly useful for basic image viewing in debugging, image processing tasks, or data analysis where a visual check is needed.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'open-cv',\n",
       " 'output': 'The function `display_image` in the provided Python script is designed to load and show an image using the OpenCV library, which is a popular library for computer vision tasks. The script is structured into three main parts: the import statement, the function definition, and an example usage. Here are the details of each part:\\n\\n1. **Import Statement:**\\n   ```python\\n   import cv2\\n   ```\\n   This line imports the OpenCV library and binds it to the name `cv2`. This import is necessary to access functions from the OpenCV library, which are used to read, display, and manipulate the image.\\n\\n2. **Function Definition:**\\n   ```python\\n   def display_image(image_path):\\n       # Read the image file\\n       image = cv2.imread(image_path)\\n       \\n       # Display the image\\n       cv2.imshow(\\'Image\\', image)\\n       cv2.waitKey(0)\\n       cv2.destroyAllWindows()\\n   ```\\n   - **Function Signature (`display_image(image_path)`):**\\n     The function is named `display_image` and takes one parameter, `image_path`, which is a string representing the filesystem path to the image file to be displayed.\\n\\n   - **Reading the Image (`cv2.imread(image_path)`):**\\n     Inside the function, `cv2.imread(image_path)` is called to load an image from the specified `image_path`. The returned result is stored in the variable `image`. This function returns the image as a numpy array if the path is valid and the file is successfully read, otherwise it returns `None`.\\n\\n   - **Displaying the Image (`cv2.imshow(\\'Image\\', image)`):**\\n     The `cv2.imshow` function creates a window named \\'Image\\' and displays the loaded image `image` in this window. If `image` is `None` because the image was not loaded properly (due to an invalid path or the file not existing), this function might generate an error because it expects a proper image array.\\n\\n   - **Waiting for a Key Press (`cv2.waitKey(0)`):**\\n     `cv2.waitKey(0)` causes the program to pause its execution until a key is pressed. The argument `0` means it will wait indefinitely for a key press. This pause allows users to view the image until they decide to proceed by pressing a key.\\n\\n   - **Closing the Windows (`cv2.destroyAllWindows()`):**\\n     After a key is pressed, `cv2.destroyAllWindows()` is called, which simply closes all the windows that were opened by the program, i.e., the \\'Image\\' window which was displaying our `image`.\\n   \\n3. **Example Usage:**\\n   ```python\\n   image_path = \\'example.jpg\\'\\n   display_image(image_path)\\n   ```\\n   In this part of the script:\\n   - An `image_path` variable is set to the string \\'example.jpg\\', specifying an image file.\\n   - The `display_image` function is then called with the `image_path` argument pointing to \"example.jpg\".\\n\\nOverall, the script is a straightforward way to load and display an image using the OpenCV library in Python, emphasizing file operations and user interaction through keyboard input to control the display of the image. The function is particularly useful for basic image viewing in debugging, image processing tasks, or data analysis where a visual check is needed.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "llm1 = ChatOpenAI(model = 'gpt-3.5-turbo', temperature = 0.8)\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template = \"You are en experienced scientist and Python Programmer. Write a function that implements the concept of {function}\"\n",
    ")\n",
    "chain1 = LLMChain(\n",
    "    llm = llm1,\n",
    "    prompt = prompt_template\n",
    ")\n",
    "\n",
    "\n",
    "llm2 = ChatOpenAI(model = 'gpt-4-turbo', temperature = 1.2)\n",
    "prompt_template = PromptTemplate(\n",
    "    template = \"Given the python function {function}, describe it in detail\"\n",
    ")\n",
    "chain2 = LLMChain(\n",
    "    llm = llm2,\n",
    "    prompt = prompt_template\n",
    ")\n",
    "\n",
    "final_chain = SimpleSequentialChain(chains = [chain1, chain2], verbose = True)\n",
    "output = final_chain.invoke('open-cv')\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The function `display_image` in the provided Python script is designed to load and show an image using the OpenCV library, which is a popular library for computer vision tasks. The script is structured into three main parts: the import statement, the function definition, and an example usage. Here are the details of each part:\n",
      "\n",
      "1. **Import Statement:**\n",
      "   ```python\n",
      "   import cv2\n",
      "   ```\n",
      "   This line imports the OpenCV library and binds it to the name `cv2`. This import is necessary to access functions from the OpenCV library, which are used to read, display, and manipulate the image.\n",
      "\n",
      "2. **Function Definition:**\n",
      "   ```python\n",
      "   def display_image(image_path):\n",
      "       # Read the image file\n",
      "       image = cv2.imread(image_path)\n",
      "       \n",
      "       # Display the image\n",
      "       cv2.imshow('Image', image)\n",
      "       cv2.waitKey(0)\n",
      "       cv2.destroyAllWindows()\n",
      "   ```\n",
      "   - **Function Signature (`display_image(image_path)`):**\n",
      "     The function is named `display_image` and takes one parameter, `image_path`, which is a string representing the filesystem path to the image file to be displayed.\n",
      "\n",
      "   - **Reading the Image (`cv2.imread(image_path)`):**\n",
      "     Inside the function, `cv2.imread(image_path)` is called to load an image from the specified `image_path`. The returned result is stored in the variable `image`. This function returns the image as a numpy array if the path is valid and the file is successfully read, otherwise it returns `None`.\n",
      "\n",
      "   - **Displaying the Image (`cv2.imshow('Image', image)`):**\n",
      "     The `cv2.imshow` function creates a window named 'Image' and displays the loaded image `image` in this window. If `image` is `None` because the image was not loaded properly (due to an invalid path or the file not existing), this function might generate an error because it expects a proper image array.\n",
      "\n",
      "   - **Waiting for a Key Press (`cv2.waitKey(0)`):**\n",
      "     `cv2.waitKey(0)` causes the program to pause its execution until a key is pressed. The argument `0` means it will wait indefinitely for a key press. This pause allows users to view the image until they decide to proceed by pressing a key.\n",
      "\n",
      "   - **Closing the Windows (`cv2.destroyAllWindows()`):**\n",
      "     After a key is pressed, `cv2.destroyAllWindows()` is called, which simply closes all the windows that were opened by the program, i.e., the 'Image' window which was displaying our `image`.\n",
      "   \n",
      "3. **Example Usage:**\n",
      "   ```python\n",
      "   image_path = 'example.jpg'\n",
      "   display_image(image_path)\n",
      "   ```\n",
      "   In this part of the script:\n",
      "   - An `image_path` variable is set to the string 'example.jpg', specifying an image file.\n",
      "   - The `display_image` function is then called with the `image_path` argument pointing to \"example.jpg\".\n",
      "\n",
      "Overall, the script is a straightforward way to load and display an image using the OpenCV library in Python, emphasizing file operations and user interaction through keyboard input to control the display of the image. The function is particularly useful for basic image viewing in debugging, image processing tasks, or data analysis where a visual check is needed.\n"
     ]
    }
   ],
   "source": [
    "print(output['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[13, 26, 39, 52, 65, 78, 91]\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.utilities import PythonREPL #type: ignore\n",
    "\n",
    "python_repl = PythonREPL()\n",
    "python_repl.run(\"print([n for n in range(1, 100) if n%13 == 0])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo solve this, I will first calculate the factorial of 12 using the `math` module's `factorial` function. Then, I will calculate the square root of that result using the `sqrt` function from the same module. Finally, I will format the result to display it with 4 decimal points using the `format` function.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: import math\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: Python_REPL\n",
      "Action Input: factorial_12 = math.factorial(12)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: Python_REPL\n",
      "Action Input: sqrt_factorial_12 = math.sqrt(factorial_12)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: Python_REPL\n",
      "Action Input: print(format(sqrt_factorial_12, '.4f'))\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m21886.1052\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 21886.1052\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Calculate the square root of the factorial of 12 and display it with 4 decimal points',\n",
       " 'output': '21886.1052'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.agents.agent_toolkits import create_python_agent     # type: ignore\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool              # type: ignore\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model = 'gpt-4-turbo-preview', temperature = 0)\n",
    "agent_executor = create_python_agent(\n",
    "    llm = llm,\n",
    "    tool = PythonREPLTool(),\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "agent_executor.invoke('Calculate the square root of the factorial of 12 and display it with 4 decimal points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to calculate 5.1 raised to the power of 7.3 to get the answer.\n",
      "Action: Python_REPL\n",
      "Action Input: print(5.1 ** 7.3)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m146306.05007233328\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 146306.05007233328\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke('What is the answer to 5.1 ** 7.3 ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the answer to 5.1 ** 7.3 ?', 'output': '146306.05007233328'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain tools: DuckDuckGo and Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Freddie Mercury (born September 5, 1946, Stone Town, Zanzibar [now in Tanzania]—died November 24, 1991, Kensington, London, England) was a British rock singer and songwriter whose flamboyant showmanship and powerfully agile vocals, most famously for the band Queen, made him one of rock\\'s most dynamic front men.. Bulsara was born to Parsi parents who had emigrated from India to Zanzibar ... Freddie Mercury always talked about his pride at writing \"Killer Queen,\" which appeared on Queen\\'s 1974 album Sheer Heart Attack. He said it was written in one night and was a song that he ... Outside of his work with Queen, Freddie Mercury recorded some solo material, including two solo albums and several singles. Read more: Queen\\'s 20 greatest ever songs His two solo albums were Mr. Bad Guy (1985) and Barcelona (1988). In 1993, a remix of \\'Living on My Own\\', posthumously reached number one in the UK. Queen are a British rock band formed in London in 1970 by Freddie Mercury (lead vocals, piano), Brian May (guitar, vocals), and Roger Taylor (drums, vocals),... Freddie Mercury and Brian May rehearsing for their first major tour on 8th July 1973 (Image credit: Michael Putland) The character of Queen was beginning to emerge. Mercury gave free reign to his natural flamboyance, sucking in a myriad of influences: Hendrix, of course, but also Bowie and glam rock, the thrilling blues power of Led Zeppelin ...'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "output = search.run('Freddie Mercury and Queen')\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('duckduckgo_search',\n",
       " 'A wrapper around DuckDuckGo Search. Useful for when you need to answer questions about current events. Input should be a search query.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.name, search.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "wrapper = DuckDuckGoSearchAPIWrapper(region = 'in-en', max_results=3, safesearch='moderate')\n",
    "output = wrapper.run('New delhi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Delhi is the national capital of India, founded in 1912 as the new seat of British colonial rule. It has a modern and spacious layout, contrasting with the ancient and crowded Old Delhi, and is home to many government buildings, museums, and parks. Delhi is the capital of India and a World Heritage site, with a rich and diverse history and culture. Learn about its geography, landmarks, wildlife, and climate from Britannica's experts. Discover the best places to visit in Delhi, India, a city with a rich history and diverse culture. Explore its ancient monuments, gardens, museums, temples, and markets in both New Delhi and Old Delhi.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Vector database\\nSummary: A vector database, vector store or vector search engine is a database that can store vectors (fixed-length lists of numbers) along with other data items. Vector databases typically implement one or more Approximate Nearest Neighbor (ANN) algorithms, so that one can search the database with a query vector to retrieve the closest matching database records.\\nVectors are mathematical representations of data in a high-dimensional space. In this space, each dimension corr'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=500)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "wiki.invoke({'query': 'llama-index'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a ReAct agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchainhub -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "LangSmithUserError",
     "evalue": "API key must be provided when using hosted LangSmith API",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLangSmithUserError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 16\u001b[0m\n\u001b[1;32m     11\u001b[0m template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124mAnswer the following questions as best you can.\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124mQuestions: \u001b[39m\u001b[38;5;132;01m{q}\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m     15\u001b[0m prompt_template \u001b[38;5;241m=\u001b[39m PromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(template)\n\u001b[0;32m---> 16\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[43mhub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpull\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhwchase17/react\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(prompt))\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(prompt\u001b[38;5;241m.\u001b[39minput_variables)\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain_env/lib/python3.12/site-packages/langchain/hub.py:110\u001b[0m, in \u001b[0;36mpull\u001b[0;34m(owner_repo_commit, include_model, api_url, api_key)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpull\u001b[39m(\n\u001b[1;32m     94\u001b[0m     owner_repo_commit: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m     api_key: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    100\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    Pull an object from the hub and returns it as a LangChain object.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m    :param api_key: The API key to use to authenticate with the LangChain Hub API.\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m     client \u001b[38;5;241m=\u001b[39m \u001b[43m_get_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# Then it's langsmith\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(client, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpull_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain_env/lib/python3.12/site-packages/langchain/hub.py:20\u001b[0m, in \u001b[0;36m_get_client\u001b[0;34m(api_key, api_url)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangsmith\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Client \u001b[38;5;28;01mas\u001b[39;00m LangSmithClient\n\u001b[0;32m---> 20\u001b[0m     ls_client \u001b[38;5;241m=\u001b[39m \u001b[43mLangSmithClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ls_client, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpush_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ls_client, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpull_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ls_client\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain_env/lib/python3.12/site-packages/langsmith/client.py:536\u001b[0m, in \u001b[0;36mClient.__init__\u001b[0;34m(self, api_url, api_key, retry_config, timeout_ms, web_url, session, auto_batch_tracing, anonymizer, hide_inputs, hide_outputs, info, api_urls)\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_url \u001b[38;5;241m=\u001b[39m ls_utils\u001b[38;5;241m.\u001b[39mget_api_url(api_url)\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m ls_utils\u001b[38;5;241m.\u001b[39mget_api_key(api_key)\n\u001b[0;32m--> 536\u001b[0m     \u001b[43m_validate_api_key_if_hosted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_api_urls \u001b[38;5;241m=\u001b[39m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_url: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key}\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_config \u001b[38;5;241m=\u001b[39m retry_config \u001b[38;5;129;01mor\u001b[39;00m _default_retry_config()\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain_env/lib/python3.12/site-packages/langsmith/client.py:333\u001b[0m, in \u001b[0;36m_validate_api_key_if_hosted\u001b[0;34m(api_url, api_key)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m api_key:\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_langchain_hosted(api_url):\n\u001b[0;32m--> 333\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ls_utils\u001b[38;5;241m.\u001b[39mLangSmithUserError(\n\u001b[1;32m    334\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI key must be provided when using hosted LangSmith API\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    335\u001b[0m         )\n",
      "\u001b[0;31mLangSmithUserError\u001b[0m: API key must be provided when using hosted LangSmith API"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import Tool, AgentExecutor, initialize_agent, create_react_agent\n",
    "from langchain.tools import DuckDuckGoSearchRun, WikipediaQueryRun\n",
    "from langchain.utilities import WikipediaAPIWrapper\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "\n",
    "llm = ChatOpenAI(model = 'gpt-3.5-turbo')\n",
    "\n",
    "template = '''\n",
    "Answer the following questions as best you can.\n",
    "Questions: {q}\n",
    "'''\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt = hub.pull('hwchase17/react')\n",
    "print(type(prompt))\n",
    "print(prompt.input_variables)\n",
    "print(prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
